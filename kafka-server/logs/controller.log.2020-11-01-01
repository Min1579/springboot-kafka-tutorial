[2020-11-01 01:56:57,200] DEBUG preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@3a4afd8d, name=log4j:logger=kafka.controller (kafka.controller)
[2020-11-01 01:58:21,991] INFO [ControllerEventThread controllerId=1001] Starting (kafka.controller.ControllerEventManager$ControllerEventThread)
[2020-11-01 01:58:22,075] INFO [Controller id=1001] 1001 successfully elected as the controller. Epoch incremented to 1 and epoch zk version is now 1 (kafka.controller.KafkaController)
[2020-11-01 01:58:22,076] INFO [Controller id=1001] Registering handlers (kafka.controller.KafkaController)
[2020-11-01 01:58:22,084] INFO [Controller id=1001] Deleting log dir event notifications (kafka.controller.KafkaController)
[2020-11-01 01:58:22,092] INFO [Controller id=1001] Deleting isr change notifications (kafka.controller.KafkaController)
[2020-11-01 01:58:22,095] INFO [Controller id=1001] Initializing controller context (kafka.controller.KafkaController)
[2020-11-01 01:58:22,165] INFO [Controller id=1001] Initialized broker epochs cache: HashMap(1001 -> 25) (kafka.controller.KafkaController)
[2020-11-01 01:58:22,174] DEBUG [Controller id=1001] Register BrokerModifications handler for Set(1001) (kafka.controller.KafkaController)
[2020-11-01 01:58:22,192] DEBUG [Channel manager on controller 1001]: Controller 1001 trying to connect to broker 1001 (kafka.controller.ControllerChannelManager)
[2020-11-01 01:58:22,237] INFO [RequestSendThread controllerId=1001] Starting (kafka.controller.RequestSendThread)
[2020-11-01 01:58:22,242] INFO [Controller id=1001] Currently active brokers in the cluster: Set(1001) (kafka.controller.KafkaController)
[2020-11-01 01:58:22,243] INFO [Controller id=1001] Currently shutting brokers in the cluster: HashSet() (kafka.controller.KafkaController)
[2020-11-01 01:58:22,244] INFO [Controller id=1001] Current list of topics in the cluster: HashSet() (kafka.controller.KafkaController)
[2020-11-01 01:58:22,244] INFO [Controller id=1001] Fetching topic deletions in progress (kafka.controller.KafkaController)
[2020-11-01 01:58:22,249] INFO [Controller id=1001] List of topics to be deleted:  (kafka.controller.KafkaController)
[2020-11-01 01:58:22,250] INFO [Controller id=1001] List of topics ineligible for deletion:  (kafka.controller.KafkaController)
[2020-11-01 01:58:22,252] INFO [Controller id=1001] Initializing topic deletion manager (kafka.controller.KafkaController)
[2020-11-01 01:58:22,257] INFO [Topic Deletion Manager 1001] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet() (kafka.controller.TopicDeletionManager)
[2020-11-01 01:58:22,259] INFO [Controller id=1001] Sending update metadata request (kafka.controller.KafkaController)
[2020-11-01 01:58:22,341] INFO [ReplicaStateMachine controllerId=1001] Initializing replica state (kafka.controller.ZkReplicaStateMachine)
[2020-11-01 01:58:22,348] INFO [RequestSendThread controllerId=1001] Controller 1001 connected to localhost:9092 (id: 1001 rack: null) for sending state change requests (kafka.controller.RequestSendThread)
[2020-11-01 01:58:22,349] INFO [ReplicaStateMachine controllerId=1001] Triggering online replica state changes (kafka.controller.ZkReplicaStateMachine)
[2020-11-01 01:58:22,361] INFO [ReplicaStateMachine controllerId=1001] Triggering offline replica state changes (kafka.controller.ZkReplicaStateMachine)
[2020-11-01 01:58:22,362] DEBUG [ReplicaStateMachine controllerId=1001] Started replica state machine with initial state -> HashMap() (kafka.controller.ZkReplicaStateMachine)
[2020-11-01 01:58:22,363] INFO [PartitionStateMachine controllerId=1001] Initializing partition state (kafka.controller.ZkPartitionStateMachine)
[2020-11-01 01:58:22,364] INFO [PartitionStateMachine controllerId=1001] Triggering online partition state changes (kafka.controller.ZkPartitionStateMachine)
[2020-11-01 01:58:22,376] DEBUG [PartitionStateMachine controllerId=1001] Started partition state machine with initial state -> HashMap() (kafka.controller.ZkPartitionStateMachine)
[2020-11-01 01:58:22,376] INFO [Controller id=1001] Ready to serve as the new controller with epoch 1 (kafka.controller.KafkaController)
[2020-11-01 01:58:22,392] INFO [Controller id=1001] Partitions undergoing preferred replica election:  (kafka.controller.KafkaController)
[2020-11-01 01:58:22,393] INFO [Controller id=1001] Partitions that completed preferred replica election:  (kafka.controller.KafkaController)
[2020-11-01 01:58:22,394] INFO [Controller id=1001] Skipping preferred replica election for partitions due to topic deletion:  (kafka.controller.KafkaController)
[2020-11-01 01:58:22,394] INFO [Controller id=1001] Resuming preferred replica election for partitions:  (kafka.controller.KafkaController)
[2020-11-01 01:58:22,397] INFO [Controller id=1001] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered (kafka.controller.KafkaController)
[2020-11-01 01:58:22,459] INFO [Controller id=1001] Starting the controller scheduler (kafka.controller.KafkaController)
[2020-11-01 01:58:27,465] INFO [Controller id=1001] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
[2020-11-01 01:58:27,467] TRACE [Controller id=1001] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
[2020-11-01 01:58:51,053] INFO [Controller id=1001] Newly added brokers: 1, deleted brokers: , bounced brokers: , all live brokers: 1,1001 (kafka.controller.KafkaController)
[2020-11-01 01:58:51,054] DEBUG [Channel manager on controller 1001]: Controller 1001 trying to connect to broker 1 (kafka.controller.ControllerChannelManager)
[2020-11-01 01:58:51,064] INFO [RequestSendThread controllerId=1001] Starting (kafka.controller.RequestSendThread)
[2020-11-01 01:58:51,071] INFO [Controller id=1001] New broker startup callback for 1 (kafka.controller.KafkaController)
[2020-11-01 01:58:51,079] DEBUG [Controller id=1001] Register BrokerModifications handler for List(1) (kafka.controller.KafkaController)
[2020-11-01 01:58:51,079] INFO [RequestSendThread controllerId=1001] Controller 1001 connected to localhost:9093 (id: 1 rack: null) for sending state change requests (kafka.controller.RequestSendThread)
[2020-11-01 01:58:51,083] INFO [Controller id=1001] Updated broker epochs cache: HashMap(1 -> 44, 1001 -> 25) (kafka.controller.KafkaController)
[2020-11-01 01:58:51,141] INFO [ControllerEventThread controllerId=1] Starting (kafka.controller.ControllerEventManager$ControllerEventThread)
[2020-11-01 01:58:51,161] DEBUG [Controller id=1] Broker 1001 has been elected as the controller, so stopping the election process. (kafka.controller.KafkaController)
[2020-11-01 01:59:14,022] INFO [Controller id=1001] Newly added brokers: 2, deleted brokers: , bounced brokers: , all live brokers: 1,2,1001 (kafka.controller.KafkaController)
[2020-11-01 01:59:14,023] DEBUG [Channel manager on controller 1001]: Controller 1001 trying to connect to broker 2 (kafka.controller.ControllerChannelManager)
[2020-11-01 01:59:14,029] INFO [Controller id=1001] New broker startup callback for 2 (kafka.controller.KafkaController)
[2020-11-01 01:59:14,032] DEBUG [Controller id=1001] Register BrokerModifications handler for List(2) (kafka.controller.KafkaController)
[2020-11-01 01:59:14,043] INFO [RequestSendThread controllerId=1001] Starting (kafka.controller.RequestSendThread)
[2020-11-01 01:59:14,044] INFO [Controller id=1001] Updated broker epochs cache: HashMap(1 -> 44, 2 -> 60, 1001 -> 25) (kafka.controller.KafkaController)
[2020-11-01 01:59:14,047] INFO [RequestSendThread controllerId=1001] Controller 1001 connected to localhost:9094 (id: 2 rack: null) for sending state change requests (kafka.controller.RequestSendThread)
[2020-11-01 01:59:14,107] INFO [ControllerEventThread controllerId=2] Starting (kafka.controller.ControllerEventManager$ControllerEventThread)
[2020-11-01 01:59:14,126] DEBUG [Controller id=2] Broker 1001 has been elected as the controller, so stopping the election process. (kafka.controller.KafkaController)
[2020-11-01 01:59:27,659] INFO [Controller id=1001] New topics: [Set(__consumer_offsets)], deleted topics: [HashSet()], new partition replica assignment [HashMap(__consumer_offsets-22 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-30 -> ReplicaAssignment(replicas=1001, addingReplicas=, removingReplicas=), __consumer_offsets-25 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-35 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=), __consumer_offsets-37 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-38 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=), __consumer_offsets-13 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-8 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=), __consumer_offsets-21 -> ReplicaAssignment(replicas=1001, addingReplicas=, removingReplicas=), __consumer_offsets-4 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-27 -> ReplicaAssignment(replicas=1001, addingReplicas=, removingReplicas=), __consumer_offsets-7 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-9 -> ReplicaAssignment(replicas=1001, addingReplicas=, removingReplicas=), __consumer_offsets-46 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-41 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=), __consumer_offsets-33 -> ReplicaAssignment(replicas=1001, addingReplicas=, removingReplicas=), __consumer_offsets-23 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=), __consumer_offsets-49 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-47 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=), __consumer_offsets-16 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-28 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-31 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-36 -> ReplicaAssignment(replicas=1001, addingReplicas=, removingReplicas=), __consumer_offsets-42 -> ReplicaAssignment(replicas=1001, addingReplicas=, removingReplicas=), __consumer_offsets-3 -> ReplicaAssignment(replicas=1001, addingReplicas=, removingReplicas=), __consumer_offsets-18 -> ReplicaAssignment(replicas=1001, addingReplicas=, removingReplicas=), __consumer_offsets-15 -> ReplicaAssignment(replicas=1001, addingReplicas=, removingReplicas=), __consumer_offsets-24 -> ReplicaAssignment(replicas=1001, addingReplicas=, removingReplicas=), __consumer_offsets-17 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=), __consumer_offsets-48 -> ReplicaAssignment(replicas=1001, addingReplicas=, removingReplicas=), __consumer_offsets-19 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-11 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=), __consumer_offsets-2 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=), __consumer_offsets-43 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-6 -> ReplicaAssignment(replicas=1001, addingReplicas=, removingReplicas=), __consumer_offsets-14 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=), __consumer_offsets-20 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=), __consumer_offsets-0 -> ReplicaAssignment(replicas=1001, addingReplicas=, removingReplicas=), __consumer_offsets-44 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=), __consumer_offsets-39 -> ReplicaAssignment(replicas=1001, addingReplicas=, removingReplicas=), __consumer_offsets-12 -> ReplicaAssignment(replicas=1001, addingReplicas=, removingReplicas=), __consumer_offsets-45 -> ReplicaAssignment(replicas=1001, addingReplicas=, removingReplicas=), __consumer_offsets-1 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-5 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=), __consumer_offsets-26 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=), __consumer_offsets-29 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=), __consumer_offsets-34 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-10 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=), __consumer_offsets-32 -> ReplicaAssignment(replicas=2, addingReplicas=, removingReplicas=), __consumer_offsets-40 -> ReplicaAssignment(replicas=1, addingReplicas=, removingReplicas=))] (kafka.controller.KafkaController)
[2020-11-01 01:59:27,660] INFO [Controller id=1001] New partition creation callback for __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-37,__consumer_offsets-38,__consumer_offsets-13,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40 (kafka.controller.KafkaController)
